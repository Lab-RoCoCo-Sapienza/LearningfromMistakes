<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Learning from Mistakes: Can LLM Self-recover after Misalignment?">
  <meta name="keywords"
    content="LLM, Alignment, Safety, Jailbreaking, Recovery, Red Teaming, AI Safety">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learning from Mistakes: Can LLM Self-recover after Misalignment?</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <link rel="stylesheet" href="./static/css/index.css">

</head>

<body>

  <!-- HERO SECTION -->
  <div class="page-section hero-section">
    <div class="inner-wide" style="text-align: center;">
      
      <!-- Dashboard Selector -->
      <div class="dashboard-selector-container">
        <select class="dashboard-selector" onchange="if(this.value) window.location.href=this.value;">
          <option value="" disabled>Select Dashboard</option>
          <option value="" selected>Learning from Mistakes</option>
          <option value="#">Guarding the Guardrails</option>
        </select>
      </div>
      
      <h1 class="title is-1 publication-title">Learning from Mistakes</h1>
      <h2 class="title is-4 publication-title">Can LLM Self-recover after Misalignment?</h2>
      
      <div class="is-size-5 publication-authors">
        <span class="author-block"><a href="https://www.linkedin.com/in/olgasorokoletova/">Olga E. Sorokoletova</a><sup>*</sup>,</span>
        <span class="author-block"><a href="https://www.linkedin.com/in/francesco-giarrusso-735759161/">Francesco Giarrusso</a><sup>*</sup>,</span>
        <span class="author-block"><a href="https://www.diag.uniroma1.it/users/vincenzo_suriani">Vincenzo Suriani</a><sup>*</sup>,</span>
        <span class="author-block"><a href="https://www.diag.uniroma1.it/nardi/">Daniele Nardi</a><sup>*</sup></span>
      </div>
      <div class="is-size-5 publication-authors" style="margin-top: 0.5rem;">
        <span class="author-block"><sup>*</sup>Sapienza University of Rome, Department of Computer, Control and Management Engineering, Italy</span>
      </div>

      <div style="margin-top: 1.5rem;">
        <a href="https://guardingtheguardrails.com/visualizer" class="visualizer-btn" target="_blank">
          <i class="fas fa-comments"></i>
          <span>Visualize the Conversations</span>
        </a>
      </div>

      <div class="buttons-row">
        <a href="#abstract" class="nav-btn"><i class="fas fa-file-alt"></i> Abstract</a>
        <a href="#methodology" class="nav-btn"><i class="fas fa-cogs"></i> Methodology</a>
        <a href="#analysis" class="nav-btn"><i class="fas fa-chart-bar"></i> Analysis</a>
        <a href="#findings" class="nav-btn"><i class="fas fa-lightbulb"></i> Key Findings</a>
      </div>
    </div>
  </div>

  <!-- ABSTRACT -->
  <div class="page-section" id="abstract">
    <div class="inner-narrow">
      <h2 class="title is-3" style="text-align: center;">Abstract</h2>
      <div style="text-align: justify;">
        <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">
          Responsible AI initiatives place great emphasis on the safety of Large Language Model (LLM)-based systems. In particular, it has become standard practice to subject these models to an alignment procedure aimed at preventing harmful outputs. However, once aligned, a model is not guaranteed to maintain this alignment throughout its lifecycle. Moreover, the likelihood of misalignment increases as malicious actors may deliberately employ jailbreaking techniques to compromise LLM safety.
        </p>
        <p style="font-size: 1.1rem; margin-bottom: 1.5rem;">
          In this paper, we introduce a <strong>new perspective on advancing LLM alignment</strong>: rather than developing stronger alignment techniques, we investigate the model's intrinsic ability to <em>recover its alignment after corruption</em>. We propose a methodology for modeling the <strong>safety trajectories</strong> of user-assistant interactions and for detecting <strong>recovery trends</strong> within them.
        </p>
        <p style="font-size: 1.1rem;">
          We apply this approach to a jailbreaking scenario, presenting a preliminary recovery analysis based on a dataset of adversarial multi-turn dialogues collected during a red teaming challenge, and examining the influence of the content moderation model chosen for safety evaluation.
        </p>
      </div>
    </div>
  </div>

  <!-- MOTIVATION -->
  <div class="page-section" id="motivation" style="background: #fafafa;">
    <div class="inner-wide">
      <h2 class="title is-3">Motivation</h2>
      <div class="info-box problem">
        <p style="font-size: 1.05rem;">
          <strong>The Problem:</strong> Many researchers agree that no system can be considered perfectly aligned and that any model's safety can eventually be compromised. This issue becomes even more critical when malicious actors deliberately attempt to compromise a model's safety through adversarial means, such as employing jailbreaking techniques.
        </p>
      </div>
      <div class="info-box approach">
        <p style="font-size: 1.05rem;">
          <strong>Our Approach:</strong> Unlike previous works that focus on developing more robust alignment methods, our study takes a different perspective. Instead of striving to design systems that never drift into misalignment, we explore how to build <em>self-recoverable LLMs</em>, models capable of finding the "road home," that is, of restoring their alignment without external intervention.
        </p>
      </div>
    </div>
  </div>

  <!-- DATASET -->
  <div class="page-section" id="dataset">
    <div class="inner-wide">
      <h2 class="title is-3">Dataset</h2>
      <p style="text-align: justify;">
        We conducted a <strong>red teaming challenge</strong> in which each participant had a two-hour session to perform multi-turn adversarial attacks. The target model was Minerva-7B-instruct-v1.0,  an instruction-tuned LLM pretrained on Italian and English corpora. Minerva is a family of LLMs developed by Sapienza NLP in the context of the Future Artificial Intelligence Research (FAIR) project, in collaboration with CINECA. After that the dataset of adversarial dialogues was collected.

      <div style="text-align: justify; margin-top: 2rem;">
        <p>
          The challenge included multiple jailbreaking tasks. Since not all tasks were compatible with the safety risk taxonomy used by Llama Guard (inherited from the MLCommons taxonomy), we selected 597 conversations out of a total of 1364. These selected dialogues correspond to tasks involving:
        </p>
        <ul style="list-style-type: disc; padding-left: 2rem; margin-top: 1rem;">
          <li>Elicitation of gender and racial bias</li>
          <li>Privacy violations</li>
          <li>Promotion of physical and non-physical harm</li>
          <li>Induction of hallucinations</li>
        </ul>
        <p style="margin-top: 1rem;">
        The challenge was conducted primarily in Italian, with a minority of prompts in English, except in cases where a specific jailbreaking technique was language-dependent.
        </p>
      </div>
    </div>
  </div>

  <!-- METHODOLOGY -->
  <div class="page-section" id="methodology" style="background: #fafafa;">
    <div class="inner-wide">
      <h2 class="title is-3">Methodology</h2>
      
      <h3 class="title is-4" style="margin-top: 2rem;">Safety Trajectories</h3>
      <div style="text-align: justify;">
        <p>
          Analyzing the temporal safety dynamics of user–LLM interactions can help to better explain incremental jailbreaks and to understand how models recover after different types of safety failures. By examining the evolution of safety states throughout a dialogue, we can trace the path from alignment to misalignment and, in some cases, to self-recovery.
        </p>
        <p style="margin-top: 1rem;">
          Once a trusted content moderation tool is chosen and safety flags are assigned, the <strong>safety trajectory</strong> is obtained by plotting these values for each user prompt and assistant response on the vertical axis against the corresponding dialogue turn on the horizontal axis.
        </p>
      </div>

      <div class="trajectory-diagram">
        <h4 class="title is-5" style="text-align: center;">Safety Trajectory Interpretation</h4>
        <div class="table-wrapper">
          <table class="data-table" style="max-width: 700px; margin: 1rem auto;">
            <thead>
              <tr>
                <th>Pattern</th>
                <th>Interpretation</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><span class="recovery-indicator recovery-safe">→ at y=0</span></td>
                <td>Benign exchange (safe prompt, safe response)</td>
              </tr>
              <tr>
                <td><span class="recovery-indicator recovery-unsafe">→ at y=1</span></td>
                <td>Successful attack (unsafe prompt, unsafe response)</td>
              </tr>
              <tr>
                <td><span class="recovery-indicator recovery-trend">↗ ascending</span></td>
                <td>Broken alignment (safe prompt, unsafe response)</td>
              </tr>
              <tr>
                <td><span class="recovery-indicator recovery-trend">↘ descending</span></td>
                <td>Resistance to attack (unsafe prompt, safe response)</td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>

      <h3 class="title is-4" style="margin-top: 2rem;">Recovery Trends</h3>
      <div style="text-align: justify;">
        <p>
          To define recovery on a safety trajectory, we first fix the turn at which an unsafe model response occurs. <strong>Recovery</strong> is then observed when the model produces the first safe response after this misalignment event.
        </p>
        
        <div class="timeline-arrow">
          <span class="timeline-step step-aligned">Aligned</span>
          <i class="fas fa-arrow-right"></i>
          <span class="timeline-step step-misaligned">Misaligned (Turn i)</span>
          <i class="fas fa-arrow-right"></i>
          <span class="timeline-step step-recovery">Recovery (Turn i+N)</span>
        </div>

        <p style="margin-top: 1rem;">We distinguish between two types of recovery:</p>
        <ul style="list-style-type: disc; padding-left: 2rem; margin-top: 0.5rem;">
          <li><strong>Absolute recovery:</strong> Restoration of alignment that is maintained until the end of the interaction</li>
          <li><strong>Temporary recovery:</strong> The model returns to alignment but later drifts into misalignment again</li>
        </ul>
      </div>
    </div>
  </div>

  <!-- ANALYSIS -->
  <div class="page-section" id="analysis">
    <div class="inner-wide">
      <h2 class="title is-3">Analysis</h2>
      
      <h3 class="title is-4" style="margin-top: 2rem;">Alignment Statistics</h3>
      <p style="text-align: justify;">
        The analysis was conducted using Llama Guard 3-1B as the baseline content moderation model, which shows 77.08% agreement with ground truth manual safety evaluation. We also compared results with Llama Guard 3-8B.
      </p>

      <div class="table-wrapper">
        <table class="data-table">
          <thead>
            <tr>
              <th>Guard Model</th>
              <th>Unsafe Conversations</th>
              <th>Conversations w/ Recoveries</th>
              <th>Multiple Recoveries</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Llama Guard 3-1B</strong></td>
              <td>202 (33.8%)</td>
              <td>87 (14.6%)</td>
              <td>19 (3.2%)</td>
            </tr>
            <tr>
              <td><strong>Llama Guard 3-8B</strong></td>
              <td>193 (32.3%)</td>
              <td>65 (10.9%)</td>
              <td>5 (0.8%)</td>
            </tr>
          </tbody>
        </table>
      </div>

      <h3 class="title is-4" style="margin-top: 2rem;">Recovery Dynamics</h3>
      <div class="table-wrapper">
        <table class="data-table">
          <thead>
            <tr>
              <th>Guard Model</th>
              <th>Avg. Turns</th>
              <th>Avg. Recoveries</th>
              <th>Avg. Turns b. Recovery</th>
              <th>Avg. Misalignment Length</th>
              <th>Avg. Recovery Duration</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><strong>Llama Guard 3-1B</strong></td>
              <td>9.8</td>
              <td>1.4</td>
              <td>4.3</td>
              <td>1.63</td>
              <td>3.69</td>
            </tr>
            <tr>
              <td><strong>Llama Guard 3-8B</strong></td>
              <td>8.3</td>
              <td>1.1</td>
              <td>5.4</td>
              <td>2.14</td>
              <td>2.34</td>
            </tr>
          </tbody>
        </table>
      </div>

      <div style="text-align: justify; margin-top: 2rem;">
        <p>Two metrics are particularly informative for characterizing alignment dynamics:</p>
        <ul style="list-style-type: disc; padding-left: 2rem; margin-top: 0.5rem;">
          <li><strong>Misalignment Length:</strong> Captures how many turns the model remains misaligned before recovery occurs. Systems more resistant to jailbreaking should minimize this value.</li>
          <li><strong>Recovery Duration:</strong> Describes how long the model stays aligned after returning to a safe state while the attack continues. Higher values indicate greater robustness to sustained adversarial pressure.</li>
        </ul>
      </div>

      <h3 class="title is-4" style="margin-top: 2rem;">Risk-Specific Effects</h3>
      <div class="table-wrapper">
      <table class="data-table">
            <thead>
            <tr>
                <th>Hazard Category</th>
                <th colspan="2" style="text-align: center;">Conversations</th>
                <th colspan="2" style="text-align: center;">Recoveries</th>
                <th colspan="2" style="text-align: center;">Avg. Misalignment Length</th>
                <th colspan="2" style="text-align: center;">Avg. Recovery Duration</th>
            </tr>
            <tr>
                <th></th>
                <th>LG 3-1B</th>
                <th>LG 3-8B</th>
                <th>LG 3-1B</th>
                <th>LG 3-8B</th>
                <th>LG 3-1B</th>
                <th>LG 3-8B</th>
                <th>LG 3-1B</th>
                <th>LG 3-8B</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td><strong>Violent Crimes</strong></td>
                <td>63</td><td>36</td>
                <td>28</td><td>9</td>
                <td>1.82</td><td>1.78</td>
                <td>2.61</td><td>2.50</td>
            </tr>
            <tr>
                <td><strong>Hate</strong></td>
                <td>60</td><td>71</td>
                <td>28</td><td>27</td>
                <td>1.25</td><td>2.63</td>
                <td>5.81</td><td>2.28</td>
            </tr>
            <tr>
                <td><strong>Non-Violent Crimes</strong></td>
                <td>28</td><td>20</td>
                <td>9</td><td>5</td>
                <td>1.33</td><td>1.80</td>
                <td>2.17</td><td>2.67</td>
            </tr>
            <tr>
                <td><strong>Indiscriminate Weapons</strong></td>
                <td>20</td><td>31</td>
                <td>6</td><td>8</td>
                <td>2.83</td><td>2.25</td>
                <td>2.25</td><td>2.20</td>
            </tr>
            <tr>
                <td><strong>Privacy</strong></td>
                <td>22</td><td>20</td>
                <td>14</td><td>10</td>
                <td>2.00</td><td>2.30</td>
                <td>3.83</td><td>1.17</td>
            </tr>
            <tr>
                <td><strong>Intellectual Property</strong></td>
                <td>16</td><td>2</td>
                <td>15</td><td>3</td>
                <td>1.80</td><td>2.00</td>
                <td>3.69</td><td>4.00</td>
            </tr>
            </tbody>
        </table>
      </div>
    </div>
  </div>

  <!-- KEY FINDINGS -->
  <div class="page-section" id="findings" style="background: #fafafa;">
    <div class="inner-wide">
      <h2 class="title is-3">Key Findings</h2>
      
      <div class="findings-grid">
        <div class="key-finding finding-success">
          <h4><i class="fas fa-check-circle"></i> Most Recoverable Categories</h4>
          <p>"Violent Crimes" and "Intellectual Property" tend to be the most recoverable categories, showing shorter misalignment lengths and longer recovery durations.</p>
        </div>
        <div class="key-finding finding-warning">
          <h4><i class="fas fa-exclamation-triangle"></i> Most Difficult to Recover</h4>
          <p>"Indiscriminate Weapons" and "Privacy" are the most difficult categories to recover from, indicating weaker self-correction capabilities in these areas.</p>
        </div>
        <div class="key-finding finding-info">
          <h4><i class="fas fa-chart-line"></i> Recovery Patterns</h4>
          <p>Misalignment episodes last on average about 2 turns, and recovery typically persists for about 3-4 turns before potential renewed misalignment.</p>
        </div>
        <div class="key-finding finding-neutral">
          <h4><i class="fas fa-balance-scale"></i>Sensitivity of the evaluation model</h4>
          <p>The larger 8B model shows higher misalignment length and shorter recovery duration compared to the 1B model</p>
        </div>
      </div>
    </div>
  </div>

  <!-- CONCLUSION -->
  <div class="page-section" id="conclusion">
    <div class="inner-narrow">
      <h2 class="title is-3">Conclusion & Future Work</h2>
      <div style="text-align: justify;">
        <p>
          This work aims to open a discussion on alignment from a new perspective. Instead of focusing solely on making models well-aligned, we suggest examining the potential for <strong>self-recovery in imperfectly aligned systems</strong>.
        </p>
        <p style="margin-top: 1rem;">
          The presented results are preliminary and depend on the specific setup of our challenge, including the choice of the attacked model, the target tasks, and their correspondence to the taxonomy used in safety evaluation.
        </p>
        <p style="margin-top: 1rem;"><strong>Future directions include:</strong></p>
        <ul style="list-style-type: disc; padding-left: 2rem; margin-top: 0.5rem;">
          <li>Exploring how to increase Recovery Duration and decrease Misalignment Length</li>
          <li>Enhancing the stability of alignment once regained</li>
          <li>Broader comparative analysis of different moderation systems</li>
          <li>Understanding how recovery behavior can deepen our understanding of alignment itself</li>
        </ul>
      </div>

      <div style="text-align: center; margin-top: 2rem;">
        <a href="https://guardingtheguardrails.com/visualizer" class="visualizer-btn" target="_blank">
          <i class="fas fa-comments"></i>
          <span>Explore the Conversation Data</span>
        </a>
      </div>
    </div>
  </div>

  <!-- FOOTER -->
  <div class="page-footer">
    <p><strong>Learning from Mistakes: Can LLM Self-recover after Misalignment?</strong></p>
    <p>Sapienza University of Rome 
  </div>

</body>
</html>